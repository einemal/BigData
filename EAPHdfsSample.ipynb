{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a sample notebook showing how to read and write directly to HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('sample-'+os.getlogin()).enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read direct paquet files from EAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = spark.read.parquet('/data/gfctocon/work/hive/prod_tlv_documents/batch_id=2500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|           thread_id|      date|             subject|\n",
      "+--------------------+----------+--------------------+\n",
      "|conversation_exch...|2019_03_05|EQRA/RiskAppsMain...|\n",
      "|conversation_exch...|2019_03_05|Philippines Econo...|\n",
      "|conversation_exch...|2019_03_05|RE: 2019 - 044 BE...|\n",
      "|conversation_exch...|2019_03_05|[PROD] CENTR Even...|\n",
      "|conversation_exch...|2019_03_05|       JFM New Issue|\n",
      "|conversation_exch...|2019_03_05|Full Checks Colo ...|\n",
      "|conversation_exch...|2019_03_05|SIT Pending Appro...|\n",
      "|conversation_exch...|2019_03_05|RE: Receipt from ...|\n",
      "|conversation_exch...|2019_03_05|(BIIB): BIIB to a...|\n",
      "|conversation_exch...|2019_03_05|Citi Sales and Tr...|\n",
      "|conversation_exch...|2019_03_05|SEV2  (INITIAL): ...|\n",
      "|conversation_exch...|2019_03_05|CTE - Expense Rep...|\n",
      "|conversation_exch...|2019_03_05| CAP Usage: $12.998B|\n",
      "|conversation_exch...|2019_03_05| RE: AMC Lender Call|\n",
      "|conversation_exch...|2019_03_05|Credit MAT RPT -2...|\n",
      "|conversation_exch...|2019_03_05|Re: Project Cali-...|\n",
      "|conversation_exch...|2019_03_05|Data Loading into...|\n",
      "|conversation_exch...|2019_03_05|OTC MARGIN : PROD...|\n",
      "|conversation_exch...|2019_03_05|CTE - Expense Rep...|\n",
      "|conversation_exch...|2019_03_05|Philippines Econo...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select('thread_id','date','subject').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the schema of the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- document_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- thread_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- message_type: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example performing Spark SQL against a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|message_type|cnt|\n",
      "+------------+---+\n",
      "|    exchange|522|\n",
      "+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.createOrReplaceTempView('dsView')\n",
    "resultDataFrame = spark.sql('select message_type,count(1) cnt from dsView group by message_type')\n",
    "resultDataFrame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(message_type='exchange', cnt=522)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDataFrame.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write dataframe to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "uniqueDirectoryName = '/data/gfctocon/work/sampleoutput-{}'.format(uuid.uuid4().hex)\n",
    "resultDataFrame.write.parquet(uniqueDirectoryName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from a local file. \n",
    "#### This will only work if spark is running in LOCAL mode\n",
    "#### If you are using a spark-defaults.conf with cluster mode then executors run on EAP and those executors cannot see this local file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = spark.read.csv('file:///test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can run a cmd shell command including our hadoop hdfs command from within jupyter. \n",
    "#### This will only work for dev because the hdfs command for uat and prod  prompts for kerberos credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New ticket is stored in cache file C:\\Users\\ae79644\\krb5cc_ae79644\n",
      "Found 87 items\n",
      "-rw-r--r--   3 gf90162  gfctocon      26743 2019-03-04 13:04 /data/gfctocon/work/CashEquity_Mantas_Alerts_20181107.csv\n",
      "drwxr-xr-x   - aa08467  gfctocon          0 2018-11-02 11:41 /data/gfctocon/work/aa08467\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2018-12-27 12:47 /data/gfctocon/work/adam\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-11-02 14:26 /data/gfctocon/work/adamtest\n",
      "drwxrwxr-x   - ch10471  gfctocon          0 2016-10-12 14:18 /data/gfctocon/work/ahi_\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2018-04-01 06:40 /data/gfctocon/work/alpha_\n",
      "-rw-r--r--   3 gfctocon gfctocon        600 2018-03-22 08:54 /data/gfctocon/work/alpha_hive_migrations\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-01-16 09:52 /data/gfctocon/work/archive\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-04 10:06 /data/gfctocon/work/benchmark\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-16 11:03 /data/gfctocon/work/bfsdev\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-01 04:58 /data/gfctocon/work/bfsdev2\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-18 11:15 /data/gfctocon/work/bfsdev3\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-07-09 10:18 /data/gfctocon/work/bfsdev3_20190709110345\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 06:53 /data/gfctocon/work/bfsdev4\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-07-09 06:02 /data/gfctocon/work/bfsdev4_20190710052211\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-07-10 05:27 /data/gfctocon/work/bfsdev4_20190710055350\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 04:58 /data/gfctocon/work/bfsdev5\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 12:22 /data/gfctocon/work/bfsdev6\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 08:45 /data/gfctocon/work/bfsdev6_20191003122138\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-05-21 18:49 /data/gfctocon/work/bfsdev_20190522083814\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-06-05 09:32 /data/gfctocon/work/bfsdev_20190605111932\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-06-05 11:20 /data/gfctocon/work/bfsdev_20190605114154\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 13:08 /data/gfctocon/work/bfstest\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-05-28 09:31 /data/gfctocon/work/bloomberg\n",
      "-rw-r--r--   3 rs39877  gfctocon      75365 2018-11-06 07:57 /data/gfctocon/work/bulk_ds.csv\n",
      "drwxrwxr-x   - ch10471  gfctocon          0 2017-04-28 12:25 /data/gfctocon/work/ch10471_\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-12 04:31 /data/gfctocon/work/dev\n",
      "drwxr-xr-x   - bs82261  gfctocon          0 2016-07-12 14:43 /data/gfctocon/work/distcp\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-02-13 07:26 /data/gfctocon/work/dora\n",
      "drwxr-x--x   - gfctocon gfctocon          0 2016-01-28 15:41 /data/gfctocon/work/elastic\n",
      "drwxrwxr-x   - gg76519  gfctocon          0 2017-02-15 07:05 /data/gfctocon/work/eng\n",
      "drwxr-xr-x   - ch10471  gfctocon          0 2017-01-10 22:08 /data/gfctocon/work/featurizertest_\n",
      "drwxr-xr-x   - gg76519  gfctocon          0 2018-05-17 09:43 /data/gfctocon/work/gili_\n",
      "drwxr-xr-x   - gv00398  gfctocon          0 2018-11-29 13:03 /data/gfctocon/work/gv00398_\n",
      "drwxrwx--x+  - hive     hive              0 2019-10-03 13:38 /data/gfctocon/work/hive\n",
      "drwxr-xr-x   - bs82261  gfctocon          0 2016-03-09 15:30 /data/gfctocon/work/input\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2017-03-02 12:46 /data/gfctocon/work/jars\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-12-30 16:28 /data/gfctocon/work/k60\n",
      "drwxr-xr-x   - kb03288  gfctocon          0 2019-01-23 07:01 /data/gfctocon/work/kb03288\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2017-08-02 13:35 /data/gfctocon/work/keytab\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2017-07-26 14:40 /data/gfctocon/work/keytabs\n",
      "drwxrwxrwx   - ka71722  gfctocon          0 2017-07-09 05:43 /data/gfctocon/work/koby_\n",
      "-rw-r--r--   3 gfctocon gfctocon        657 2018-09-05 07:21 /data/gfctocon/work/migration.out\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 07:44 /data/gfctocon/work/models1\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-09 12:17 /data/gfctocon/work/models2\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-02-04 13:23 /data/gfctocon/work/models3\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-01-15 06:45 /data/gfctocon/work/nftperftesting\n",
      "drwxrwx--x   - gfctocon gfctocon          0 2017-12-25 06:25 /data/gfctocon/work/nightly-ctc-3415\n",
      "-rw-r--r-x   3 gfctocon gfctocon        290 2017-08-13 06:27 /data/gfctocon/work/nightly_hive_migrations\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-07-10 11:18 /data/gfctocon/work/nlpichs\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-08-14 19:17 /data/gfctocon/work/participantcaching\n",
      "drwxr-xr-x   - pc79648  gfctocon          0 2017-08-02 04:54 /data/gfctocon/work/paulc\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-01-31 07:18 /data/gfctocon/work/pm76061\n",
      "drwxr-xr-x   - pm99403  gfctocon          0 2019-02-11 09:20 /data/gfctocon/work/pm99403\n",
      "drwxr-xr-x   - bs82261  gfctocon          0 2016-12-02 17:31 /data/gfctocon/work/postProcessWorkflow\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 10:01 /data/gfctocon/work/prod\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-05-27 07:54 /data/gfctocon/work/prod_20180529113542\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-05-21 06:51 /data/gfctocon/work/prod_20190521173825\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-05-22 03:29 /data/gfctocon/work/prod_20190522071747\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-11 17:22 /data/gfctocon/work/prodsupport\n",
      "drwxrwxrwx   - as03053  gfctocon          0 2017-06-06 18:08 /data/gfctocon/work/proximity\n",
      "-rw-r--r-x   3 as03053  gfctocon   11617667 2016-03-07 16:29 /data/gfctocon/work/proximity\n",
      "\n",
      "drwxrwxrwx   - bs82261  gfctocon          0 2017-05-25 15:05 /data/gfctocon/work/proximity_staging\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-12 08:09 /data/gfctocon/work/qa\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-23 11:11 /data/gfctocon/work/qa2\n",
      "drwxr-xr-x   - rs39877  gfctocon          0 2016-09-01 03:41 /data/gfctocon/work/ran_\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-10-03 11:45 /data/gfctocon/work/research\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-09 11:56 /data/gfctocon/work/rnd3\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-09-28 10:09 /data/gfctocon/work/rt64601_test\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-01-14 08:40 /data/gfctocon/work/sparkpoc\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-26 08:21 /data/gfctocon/work/spock\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-05-15 07:45 /data/gfctocon/work/spock_nft\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2018-11-21 17:24 /data/gfctocon/work/tcactors\n",
      "-rw-r--r--   3 bs82261  gfctocon       6388 2017-10-03 18:19 /data/gfctocon/work/temp\n",
      "drwxr-xr-x   - gg76519  gfctocon          0 2016-12-04 16:29 /data/gfctocon/work/test\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-09-27 07:23 /data/gfctocon/work/test1\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-05-20 09:06 /data/gfctocon/work/test1_20190522073353\n",
      "drwxrwxr-x   - ka71722  gfctocon          0 2016-07-28 04:17 /data/gfctocon/work/tlv\n",
      "drwxrwx--x   - gfctocon gfctocon          0 2018-03-25 09:25 /data/gfctocon/work/tmp\n",
      "-rw-r--r--   3 gfctocon gfctocon        123 2018-09-05 04:10 /data/gfctocon/work/tmp.status\n",
      "-rw-r--r--   3 gfctocon gfctocon        449 2018-09-05 03:46 /data/gfctocon/work/tmp.statusbeeline\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-01-22 08:11 /data/gfctocon/work/tmpmsgs\n",
      "drwxr-xr-x   - as03053  gfctocon          0 2016-03-23 12:19 /data/gfctocon/work/totalconduct\n",
      "drwxr-xr-x   - gfctocon gfctocon          0 2019-09-17 16:37 /data/gfctocon/work/uno_reviews\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2018-12-17 08:27 /data/gfctocon/work/vb03900\n",
      "drwxrwxrwx   - gfctocon gfctocon          0 2019-03-22 05:59 /data/gfctocon/work/wb\n",
      "drwxrwx--x   - gg76519  gfctocon          0 2017-11-15 18:28 /data/gfctocon/work/work\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Djava.security.krb5.conf=C:\\Users\\ae79644\\adamrepo\\hadoop\\bin\\\\..\\conf\\dev\\krb5.conf\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/C:/Users/ae79644/adamrepo/hadoop/jars/pig-0.12.0-cdh5.9.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/C:/Users/ae79644/adamrepo/hadoop/jars/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/C:/Users/ae79644/adamrepo/hadoop/jars/slf4j-simple-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Picked up _JAVA_OPTIONS: -Djava.security.krb5.conf=C:\\Users\\ae79644\\adamrepo\\hadoop\\bin\\\\..\\conf\\dev\\krb5.conf\n"
     ]
    }
   ],
   "source": [
    "!hdfs dev dfs -ls /data/gfctocon/work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
